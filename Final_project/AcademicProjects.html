<!doctype html>
<html lang="en-US">



<head>
<meta charset="utf-8">

	<title>
	 Portfolio
	</title>

	<link rel="stylesheet" type="text/css" href="mobile.css">
</head>

<body>


<nav class="navbar">
    <div class="navbar-container container">
        <input type="checkbox" name="" id="">
        <div class="hamburger-lines">
            <span class="line line1"></span>
            <span class="line line2"></span>
            <span class="line line3"></span>
        </div>
        <ul class="menu-items">
			<li><a href="http://141.217.120.86/hi6288/html/inf6420-projects/6420-final/">Home</a></li>
			<li><a href="http://141.217.120.86/hi6288/html/inf6420-projects/6420-final/profile.html">Profile</a></li>
			<li><a href="http://141.217.120.86/hi6288/html/inf6420-projects/6420-final/CVResumepage.html">Resume</a></li>
			<li><a href="http://141.217.120.86/hi6288/html/inf6420-projects/6420-final/IndustrialProjects.html">Industrial Projects</a></li>
			<li><a href="http://141.217.120.86/hi6288/html/inf6420-projects/6420-final/AcademicProjects.html">Academic Publications</a></li>
			<li><a href="http://141.217.120.86/hi6288/html/inf6420-projects/6420-final/ContactMeForm.html">Contact me</a></li>
        </ul>
        <h1 class="logo">PW</h1>
    </div>
</nav>

	<section class="showcase-area" id="showcase">
		<div class="showcase-container">
        		<h1 class="main-title" id="home">Academic Publications</h1>
    		</div>
	</section>

	<section id="about">
	    <div class="about-wrapper container">

	            <p>On this page you will find a couple of the research publications that I have helped to study and write over the last several years. In these publications, similar to the videos found on the Industrial Projects page, the research is broken down and explained and our findings are laid out in a cohesive and mind-wracking format to better answer the questions of the future of Virtual Reality technology.</p>



			<ol>
	&nbsp;<li><h3> <a href="files/eyes_free.pdf"> Eyes-Free Target Acquisition in Interaction Space around the Body for Virtual Reality </a> </h3></li>


		<small> Abstract: Eyes-free target acquisition is a basic and important human ability to interact with the surrounding physical world, relying on the sense of space and proprioception. In this research, we leverage this ability to improve interaction in virtual reality (VR), by allowing users to acquire a virtual object without looking at it. We expect this eyes-free approach can effectively reduce head movements and focus changes, so as to speed up the interaction and alleviate fatigue and VR sickness. We conduct three lab studies to progressively investigate the feasibility and usability of eyes-free target acquisition in VR. Results show that, compared with the eyes-engaged manner, the eyes-free approach is significantly faster, provides satisfying accuracy, and introduces less fatigue and sickness; Most participants (13/16) prefer this approach. We also measure the accuracy of motion control and evaluate subjective experience of users when acquiring targets at different locations around the body. Based on the result, we make suggestions on designing appropriate target layout and discuss several design issues for eyes-free target acquisition in VR.&nbsp; </small>


				<li><h3> <a href="files/reducing_arm_fatigue.pdf"> Reducing Arm Fatigue in Virtual Reality by Introducing 3D-Spatial Offset </a> </h3></li>

		<small> Abstract: Arm fatigue is an important factor affecting user experience in Virtual Reality (VR). In this work, we have proposed ProxyHand and StickHand, virtual hand techniques to address this issue. Using ProxyHand or StickHand, users can flexibly adjust the 3D-spatial offset between the physical hand and its virtual representation. This will allow users to keep their arms in a comfortable posture (vertically down) even when they have to manipulate objects in locations that require lifting of arms using the default interaction method. Proposed ProxyHand and StickHand have a similar Underlying concept that is to introduce a 3D-spatial offset between the physical hand and its virtual representation in VR. However, they respond differently to the userâ€™s hand movements because of different working mechanisms. Question arises whether the 3D-spatial offset will negatively impact the hand control ability as the directness of interaction is being violated. To investigate this, we conducted user studies where users were
		    asked to perform object translation, rotation and hybrid tasks. ProxyHand and StickHand are used in combination in some scenarios to maximize positive impact on the user experience in VR. This raises the question to find the best possible combination of these virtual hands to reduce arm fatigue. Firstly, for this purpose, we combined both virtual hands by manually allowing users to switch between ProxyHand and StickHand. Secondly, we used machine learning to automatically switch between both the virtual hands. Results showed that introduction of a 3D-spatial offset largely reduced the arm fatigue while offering equal performance to the default interaction method for all these tasks; translation, rotation and hybrid task. Users preferred using ProxyHand and StickHand to interact in the VR environment for longer periods of time. </small>

			</ol>
		</div>
	</section>
<footer id="footer">
    <h2>Hasan, Kathleen & Andrew &copy; all rights reserved</h2>
</footer>


</body>

</html>